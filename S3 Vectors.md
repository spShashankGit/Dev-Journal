# S3 Vectors


List of data points in the phone. All of these photos have:
1. Machine readable name,
2. Resolution or frame rate and
3. Size of the artifact in storage etc.

While these information is quite good to understand the type of data format it does not describe the image to us.
For example: 
<img width="198" height="207" alt="image" src="https://github.com/user-attachments/assets/5293bb11-f669-4369-8036-e8a459add67a" />
The way to describe this image is that there is dog sitting infront of the two chairs.
The dog seems to be sitting slightly to the right of the centre of two chairs.
There is an light-up AWS logo in the background.
The room appears to have to have orangish yellow light.

COmputer know all about the physcial characterstic of our data but they cannot directly calculate meaning only human can do that.

Vector tries to bridge that gap.


Vector is a large list of numerical values, generated by the large list of embeddig model and these value represent all the characterstic of that given data. So:
1. Is there a dog in the picture
2. Is there a chair in the picture
3. Is it indoors or outdooes
4. What colour is the room
5. ... and other dimensions

As models progresses we get more and more accurately represent reality. 
**This gives us interesting capabilites to mathematically quantify similarities and disimilarities**
What it gives us is that go through a large dataset which is otherwise unsorted and give us categories that are meaningful to humans.

Example:

<img width="629" height="359" alt="image" src="https://github.com/user-attachments/assets/dae951bd-45da-4fbe-91af-3fb14e96ae8d" />
This we can do by comparing the mathematical value of the vector that we derive from one piece of data and another.
We can calculate the distance between one data point and another.
We can also cluster data poitns together, this cluster represent data that have similar meaning.

Now we can load of this in the vector store and build applications that can effectively calculate the similarities and differences and do grouping across thousands of dimensions.
This is very important for the agents to behave human like i.e. they can figure out the similar items together. 

The idea of replicationg hte reality in the equation is not new, we have been trying to model the realitxy in eqiation is a age old mathematical probiem. Example: Orientation the rocket into the outer space is a question of identifying the x,y & z cordinates.


### How to find the nearest neighbour of the new piece of data?
Calculate the vector of the new image/data points using the same embedding model and then compare it with other datapoints how similar or dissimilar it is with other data points across a particular dimension.

#### Semantic Search
This ability to find and identify similar bits of data
in terms of meaning is called **semantic search**. And this is the **foundation of how all modern AI systems** retrieve and interact with information.

**Insight:**
Metadata for the text can be bigger then the text storage itself. This goes to show how much meaning is threre in the human language.
<img width="400" height="325" alt="image" src="https://github.com/user-attachments/assets/ded42886-b810-4762-96f1-1dc4b8f9a352" />
1GB of text could have approx 2.3 GB of metadata.

With RAG 100s of milisecond can be traded for the lower storage cost make sense.

Semantic search on video, where video are retrieved from glacier archive, for this usecase.. trading latency for the storage cost is a very viable option.
<img width="400" height="325" alt="image" src="https://github.com/user-attachments/assets/64d5dc1c-c87e-4591-889b-ea424bf7cc61" />

After speaking with customer it has been identified:
1. Growing new dataset that need reliable storage.
2. Workloads willing to trade-off latency for a lower storatge cost.
What is why S3 verctor is launced that is a native vector store in S3 that reduced the cost of vector storage by upto 90%.
It gves you latency upto 100ms range,
store upto 2 Billion vector per index and
upto 10,000 indexes per vector bucket.


## Reference
1. https://youtu.be/Sy2LHRyMXAo?si=S0gJHmCfeuheXLRz&t=2584
