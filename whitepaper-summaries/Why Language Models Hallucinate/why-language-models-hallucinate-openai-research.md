# Why languag Models Hallucinate

### Paper premise:
> We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline.
> We then argue that hallucinations persist due to the way most evaluations are graded—language models are optimized to be good test-takers, and guessing when uncertain improves test performance.

#### One possible reason for Hallucination
> Hallucinations need not be mysterious—they originate simply as errors in binary classification.