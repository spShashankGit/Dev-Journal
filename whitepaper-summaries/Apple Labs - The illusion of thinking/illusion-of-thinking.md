# Illusion of thinking


LRM = Large Reasoning Models
LRM = They generate detailsed thinking process before providing answers.

Limitation of LRM
1. While these models demonstrate improved performance on reasoning benchmarks, their fundamental capabilities, scaling properties, and limitations remain insufficiently understood. 

2. Current evaluations primarily focus on established mathematical and coding benchmarks, emphasizing final answer accuracy.
Source of whitepaper: 
Reference: https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf, accessed on 07.09.2025